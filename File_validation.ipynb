{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "File validation",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysql3Ej3xtoe",
        "outputId": "425ea65f-9685-42d0-c93b-1b2d12137845"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Coa_bOQx-_V",
        "outputId": "ab264233-932d-4659-ef28-a4cedb4804a9"
      },
      "source": [
        "% cd '/content/gdrive/My Drive/Datasets/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzvgPlWayHFe",
        "outputId": "4fe0500a-6f6f-4b78-d109-2aaaa14819f2"
      },
      "source": [
        "!pip install \"dask[dataframe]\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Collecting fsspec>=0.6.0; extra == \"dataframe\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/11/f7689b996f85e45f718745c899f6747ee5edb4878cadac0a41ab146828fa/fsspec-0.9.0-py3-none-any.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 10.3MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10; extra == \"dataframe\"\n",
            "  Downloading https://files.pythonhosted.org/packages/41/94/360258a68b55f47859d72b2d0b2b3cfe0ca4fbbcb81b78812bd00ae86b7c/partd-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.23.0; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.1.5)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.13.0; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]) (3.10.1)\n",
            "Collecting locket\n",
            "  Downloading https://files.pythonhosted.org/packages/50/b8/e789e45b9b9c2db75e9d9e6ceb022c8d1d7e49b2c085ce8c05600f90a96b/locket-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (1.15.0)\n",
            "Installing collected packages: fsspec, locket, partd\n",
            "Successfully installed fsspec-0.9.0 locket-0.2.1 partd-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xRvvJOdyPBk",
        "outputId": "0b4ee925-b58c-4a68-ba2b-9997399956d6"
      },
      "source": [
        "! pip install pyaml"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyaml\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml) (3.13)\n",
            "Installing collected packages: pyaml\n",
            "Successfully installed pyaml-20.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk7Nv_RzyT6f"
      },
      "source": [
        "from pyaml import yaml\n",
        "import dask.dataframe as dd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROfEfroEyWo3",
        "outputId": "a34d2df3-391a-4306-e962-ebc8f4d9fbe5"
      },
      "source": [
        "with open('config.yaml', 'r') as f:\n",
        "  config_file = yaml.safe_load(f)\n",
        "\n",
        "print(config_file)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'File format': 'tsv', 'Separator': '\\t', 'Columns': ['Language', 'Source', 'Date', 'Text'], 'Number of columns': 4, 'Max number of rows admitted': 20000000, 'Max size admitted': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh0mkonMyaoV"
      },
      "source": [
        "def Pipeline(file_name: str) -> str:\n",
        "  # 1. read the file using the YAML configuration file\n",
        "  file_format = config_file['File format']\n",
        "  data = dd.read_csv(f'{file_name}.{file_format}', sep = config_file['Separator'])\n",
        "\n",
        "  # 2. validate columns\n",
        "  if len(config_file['Columns']) == len(data.columns) and list(config_file['Columns']) == list(data.columns):\n",
        "    control_1 = 1\n",
        "  else:\n",
        "    control_1 = 0\n",
        "\n",
        "  # 3. validate number of rows\n",
        "  if len(data.iloc[:,0]) < config_file['Max number of rows admitted']:\n",
        "    control_2 = 1\n",
        "  else:\n",
        "    control_2 = 0\n",
        "  \n",
        "  # 4. validate size\n",
        "  import os\n",
        "  if os.path.getsize(f'{file_name}.{file_format}') < config_file['Max size admitted'] * 1e9:\n",
        "    control_3 = 1\n",
        "  else:\n",
        "    control_3 = 0\n",
        "\n",
        "  if control_1 + control_2 + control_3 == 3:\n",
        "    return print('The file has passed the validation and can be compressed')\n",
        "  else:\n",
        "    print('The validation failed')\n",
        "\n",
        "def summary(file_name):\n",
        "\n",
        "  file_format = config_file['File format']\n",
        "  data = dd.read_csv(f'{file_name}.{file_format}', sep = config_file['Separator'])\n",
        "  \n",
        "  num_of_cols = len(data.columns)\n",
        "  num_of_rows = len(data.iloc[:,0])\n",
        "  import os\n",
        "  file_size = os.path.getsize(f'{file_name}.{file_format}')\n",
        "\n",
        "  return print(f'The file entered was {file_name}. It has {num_of_cols} columns and {num_of_rows} entries. It weighs {file_size / 1e9} GB.')\n",
        "\n",
        "def compression(file_name, new_file_name, format):\n",
        "\n",
        "  import csv\n",
        "\n",
        "  file_format = config_file['File format']\n",
        "  with open(f'{file_name}.{file_format}', 'r') as input_f:\n",
        "    csv_reader = csv.reader(input_f, delimiter = config_file['Separator'])\n",
        "\n",
        "    with open(f'{new_file_name}.{format}', 'w') as output_f:\n",
        "      csv_writer = csv.writer(output_f, delimiter = '|')\n",
        "\n",
        "      for line in csv_reader:\n",
        "        csv_writer.writerow(line)\n",
        "      \n",
        "  import gzip\n",
        "  import shutil\n",
        "\n",
        "  with open(f'{new_file_name}.{format}', 'rb') as input_compressed:\n",
        "    with gzip.open(f'{new_file_name}.gz', 'wb') as output_compressed:\n",
        "      shutil.copyfileobj(input_compressed, output_compressed)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyNIRhZ802JO",
        "outputId": "f2e5eced-f2db-473c-bfe8-cc9785d88020"
      },
      "source": [
        "Pipeline(\"old-newspaper\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The file has passed the validation and can be compressed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QitQkr57ju0",
        "outputId": "48007d20-a707-448d-85f3-5b180c0b3747"
      },
      "source": [
        "summary('old-newspaper')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The file entered was old-newspaper. It has 4 columns and 16806041 entries. It weighs 6.024697599 GB.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tubO3DuI8ISn"
      },
      "source": [
        "# it works, although it takes longer as the file size increases\n",
        "# in this case it's a 6 GB file\n",
        "#compression('old_newspaper', 'old-newspaper-compressed', 'csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}